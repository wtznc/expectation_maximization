{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation-Maximization (EM) Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EM algorithm, a widely used approach to learning in the presence of unobserved variables. The EM algorithm can be used even for variables whose value is never directly observed, provided the general form of the probability distribution governing these variables is known.\n",
    "\n",
    "The EM algorithm has been used to train Bayesian belief networks (see Heckerman, 1995) as well as radial basis function networks. The EM algorithm is also the basis for many unsupervised clustering algorithms (e.g., Cheeseman et al. 1988), and it is the basis for the widely used Baum-Welch forward-backward algorithm for learning Partially Observable Markov Models (Rabiner, 1989).\n",
    "\n",
    "To simplify our discussion, we consider the special case where the selection of the single normal distribution at each step is based on choosing each with uniform probability, where each of the k normal distributions has the same variance s^2 and where s^2 is known.\n",
    "\n",
    "The learning task is to output a hypothesis h = (mu1, mu2) that describes the means of each of the k distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T23:06:18.536076Z",
     "start_time": "2019-08-27T23:06:18.531544Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T23:06:18.794755Z",
     "start_time": "2019-08-27T23:06:18.698902Z"
    }
   },
   "outputs": [],
   "source": [
    "# mixture of two gaussian distributions\n",
    "gauss = {'1': [1, 2], '2': [9, 2]}\n",
    "values = []\n",
    "for x in range(0, 2000):\n",
    "    choice = np.random.choice(np.arange(1,3), p=[0.5, 0.5])\n",
    "    values.append(np.random.normal(gauss[str(choice)][0], gauss[str(choice)][1], 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T23:06:18.872300Z",
     "start_time": "2019-08-27T23:06:18.864314Z"
    }
   },
   "outputs": [],
   "source": [
    "# applied to the problem of estimating the two means,\n",
    "# the EM algorithm first initializes the hypothesis to h = (mu1, mu2)\n",
    "# where mu1 and mu2 are arbitrary initial values\n",
    "h = [0, 1]\n",
    "sigma = 2\n",
    "data = np.array(values)\n",
    "\n",
    "# number of examples, number of mixture models\n",
    "probs = np.zeros((2000, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T23:06:19.713297Z",
     "start_time": "2019-08-27T23:06:19.042685Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the expected value E[zij] of each hidden variable zij,\n",
    "# assuming the current hypothesis means = [mu1, mu2] holds\n",
    "\n",
    "for x in range(0, 20): # 20 epochs\n",
    "    # ESTIMATION STEP\n",
    "    for i in range(0, len(data)):\n",
    "        for j in range(0, 2):\n",
    "            nom = np.exp((-1/2*sigma**2))*(data[i] - h[j])**2\n",
    "            denom = 0\n",
    "            for n in range(0, 2):\n",
    "                denom += np.exp((-1/2*sigma**2))*(data[i] - h[n])**2\n",
    "            final = nom / denom\n",
    "            probs[i][j] = final\n",
    "\n",
    "    # MAXIMIZATION STEP\n",
    "    for js in range(0, 2): # in range from 0 to number of mixtures\n",
    "        h[js] = np.sum(probs[:,js] * data) / np.sum(probs[:,js])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T23:06:44.201084Z",
     "start_time": "2019-08-27T23:06:44.191946Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    true means:\n",
    "    mu1 = 1;\n",
    "    mu2 = 9\n",
    "    \n",
    "    discovered means:\n",
    "    h1 = 1.2505185877110228\n",
    "    h2 = 8.611216067889572\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T23:06:44.761303Z",
     "start_time": "2019-08-27T23:06:44.749861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2505185877110228, 8.611216067889572]"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
